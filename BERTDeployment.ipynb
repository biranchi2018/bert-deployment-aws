{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sagemaker variables\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/bert-pytorch'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-29 06:48:15--  https://gradient-fire.s3.amazonaws.com/model.pth\n",
      "Resolving gradient-fire.s3.amazonaws.com (gradient-fire.s3.amazonaws.com)... 52.216.98.147\n",
      "Connecting to gradient-fire.s3.amazonaws.com (gradient-fire.s3.amazonaws.com)|52.216.98.147|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 437983063 (418M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘model.pth’\n",
      "\n",
      "model.pth           100%[===================>] 417.69M  61.9MB/s    in 6.7s    \n",
      "\n",
      "2020-02-29 06:48:22 (62.6 MB/s) - ‘model.pth’ saved [437983063/437983063]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download our trained model to the notebook runtime\n",
    "!wget https://gradient-fire.s3.amazonaws.com/model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tar file from the model file\n",
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('model.pth', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model artifacts to S3\n",
    "model_artifact = sagemaker_session.upload_data(path=model_path, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-800756380562/sagemaker/bert-pytorch/model.tar.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# setup the RealTimePredictor object for serializing the inputs to tensors for pytorch\n",
    "class StringPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')\n",
    "\n",
    "# build the sagemaker model\n",
    "model = PyTorchModel(model_data=model_artifact,\n",
    "                     role = role,\n",
    "                     framework_version='1.0.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='serve',\n",
    "                     predictor_cls=StringPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------!"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy the model as an endpoint\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-pytorch-2020-02-29-07-02-00-055'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "predictor.predict(\"Exciting, entertaining, and emotionally impactful,\\\n",
    "Avengers: Endgame does whatever it takes to deliver a satisfying finale to Marvel's epic Infinity Saga.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "predictor.predict(\"To go even further, the Marvel Studios \\\n",
    "films are so bad precisely because they are good. Even when \\\n",
    "these films are firing on all cylinders – milking their computerized \\\n",
    "action set-pieces for maximum whiz-bang effect, nailing their glib one-liners,\\\n",
    "purposefully commanding a requisite sense of seriousness from their sprawling \\\n",
    "cast of superpowered characters – their impact on the motion-picture arts amounts \\\n",
    "to a net negative. They privilege sameness over invention, to such a fatal extent\\\n",
    "that even modest revisions on the established formula (as in the much-ballyhooed \\\n",
    "Thor: Ragnarok) are praised to wild excess. Their baseline tradition of passable quality \\\n",
    "inures us to demanding anything better, or anything else at all, really.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Lambda\n",
    "\n",
    "Setup up a lambda function with the following code\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    # The SageMaker runtime is what allows us to invoke the endpoint that we've created.\n",
    "    runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "    # Now we use the SageMaker runtime to invoke our endpoint, sending the review we were given\n",
    "    response = runtime.invoke_endpoint(EndpointName = '<ENDPOINT NAME>',    # The name of the endpoint we created\n",
    "                                       ContentType = 'text/plain',                 # The data format that is expected\n",
    "                                       Body = event['body'])                       # The actual review\n",
    "\n",
    "    # The response is an HTTP response whose body contains the result of our inference\n",
    "    result = response['Body'].read().decode('utf-8')\n",
    "\n",
    "    return {\n",
    "        'statusCode' : 200,\n",
    "        'headers' : { 'Content-Type' : 'text/plain', 'Access-Control-Allow-Origin' : '*' },\n",
    "        'body' : result\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
